(window.webpackJsonp=window.webpackJsonp||[]).push([[14],{381:function(t,s,a){"use strict";a.r(s);var n=a(25),e=Object(n.a)({},(function(){var t=this,s=t.$createElement,a=t._self._c||s;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("h1",{attrs:{id:"reference"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#reference"}},[t._v("#")]),t._v(" Reference")]),t._v(" "),a("div",{staticClass:"custom-block warning"},[a("p",{staticClass:"custom-block-title"},[t._v("NOTE")]),t._v(" "),a("p",[t._v("Reference is not yet implemented in the parser.")]),t._v(" "),a("p",[t._v("REAM reference is inspired by YAML's anchor and alias, and is my implementation for "),a("a",{attrs:{href:"https://github.com/toml-lang/toml/issues/13",target:"_blank",rel:"noopener noreferrer"}},[t._v("this rejected feature for TOML"),a("OutboundLink")],1),t._v(".")]),t._v(" "),a("p",[t._v("Another inspiration for referencing is my wrong understanding of how inheritances work in object-oriented programming.\nI initially thought inheritances works with "),a("em",[t._v("instances")]),t._v(", and child instances are able to call parent instances' attributes and methods.")]),t._v(" "),a("p",[t._v('It turns out that what I was thinking was similar to a programming paradigm called "environmental acquisition" '),a("a",{attrs:{href:"https://www.cs.technion.ac.il/users/wwwb/cgi-bin/tr-get.cgi/1995/LPCR/LPCR9507.pdf",target:"_blank",rel:"noopener noreferrer"}},[t._v("(Gil & Lorenz, 1995)"),a("OutboundLink")],1),t._v(" but there is almost no implementation for it.\nThe only one I could find is the python package "),a("a",{attrs:{href:"https://github.com/zopefoundation/Acquisition",target:"_blank",rel:"noopener noreferrer"}},[t._v("Acquisition"),a("OutboundLink")],1),t._v(", and a simple illustration of how it work is as follows:")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" ExtensionClass"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Acquisition\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Country")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ExtensionClass"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Base"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("__init__")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" name"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("name "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" name\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Language")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Acquisition"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Implicit"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("__init__")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" name"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("name "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" name\n\nbelgium "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Country"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Belgium"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nflemish "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Language"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Flemmish"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nflemish"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("country "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" belgium\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("flemish"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("country"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("name"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Belgium")]),t._v("\n")])])]),a("p",[a("code",[t._v("belgium")]),t._v(" is a "),a("code",[t._v("Country")]),t._v(" object, and "),a("code",[t._v("flemish")]),t._v(" is a "),a("code",[t._v("Language")]),t._v(" object.\nWhile "),a("code",[t._v("Language")]),t._v(" is not a subclass of "),a("code",[t._v("Country")]),t._v(", I can make "),a("code",[t._v("flemish")]),t._v(" acquire the attribute "),a("code",[t._v("name")]),t._v(" from "),a("code",[t._v("belgium")]),t._v(".")]),t._v(" "),a("p",[t._v("The preliminary design is as follows.")]),t._v(" "),a("p",[t._v("(The syntax highlighting is a bit messed up)")]),t._v(" "),a("p",[t._v("Example 1:")]),t._v(" "),a("div",{staticClass:"language-ream extra-class"},[a("pre",{pre:!0,attrs:{class:"language-ream"}},[a("code",[a("span",{pre:!0,attrs:{class:"token header"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("#")]),t._v(" CountryYear")]),a("span",{pre:!0,attrs:{class:"token keyValuePair"}},[t._v("\n"),a("span",{pre:!0,attrs:{class:"token key"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" country (String)")]),a("span",{pre:!0,attrs:{class:"token semiolon punctuation"}},[t._v(": ")]),a("span",{pre:!0,attrs:{class:"token value string"}},[t._v("Belgium")])]),a("span",{pre:!0,attrs:{class:"token keyValuePair"}},[t._v("\n"),a("span",{pre:!0,attrs:{class:"token key"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" year (String)")]),a("span",{pre:!0,attrs:{class:"token semiolon punctuation"}},[t._v(": ")]),a("span",{pre:!0,attrs:{class:"token value string"}},[t._v("2020")])]),a("span",{pre:!0,attrs:{class:"token keyValuePair"}},[t._v("\n"),a("span",{pre:!0,attrs:{class:"token key"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" unique_id (fn -> String)")]),a("span",{pre:!0,attrs:{class:"token semiolon punctuation"}},[t._v(": ")]),a("span",{pre:!0,attrs:{class:"token value string"}},[t._v("`THIS")]),a("span",{pre:!0,attrs:{class:"token value number"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("$")]),t._v("country + '_' + THIS"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("$")])]),a("span",{pre:!0,attrs:{class:"token value string"}},[t._v("year`")])]),t._v("\n")])])]),a("p",[t._v("The keyword "),a("code",[t._v("THIS")]),t._v(" can be omitted if it is followed by a local attribute:")]),t._v(" "),a("div",{staticClass:"language-ream extra-class"},[a("pre",{pre:!0,attrs:{class:"language-ream"}},[a("code",[a("span",{pre:!0,attrs:{class:"token header"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("#")]),t._v(" CountryYear")]),a("span",{pre:!0,attrs:{class:"token keyValuePair"}},[t._v("\n"),a("span",{pre:!0,attrs:{class:"token key"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" country (String)")]),a("span",{pre:!0,attrs:{class:"token semiolon punctuation"}},[t._v(": ")]),a("span",{pre:!0,attrs:{class:"token value string"}},[t._v("Belgium")])]),a("span",{pre:!0,attrs:{class:"token keyValuePair"}},[t._v("\n"),a("span",{pre:!0,attrs:{class:"token key"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" year (String)")]),a("span",{pre:!0,attrs:{class:"token semiolon punctuation"}},[t._v(": ")]),a("span",{pre:!0,attrs:{class:"token value string"}},[t._v("2020")])]),a("span",{pre:!0,attrs:{class:"token keyValuePair"}},[t._v("\n"),a("span",{pre:!0,attrs:{class:"token key"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" unique_id (fn -> String)")]),a("span",{pre:!0,attrs:{class:"token semiolon punctuation"}},[t._v(": ")]),a("span",{pre:!0,attrs:{class:"token value string"}},[t._v("`")]),a("span",{pre:!0,attrs:{class:"token value number"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("$")]),t._v("country + '_' + "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("$")])]),a("span",{pre:!0,attrs:{class:"token value string"}},[t._v("year`")])]),t._v("\n")])])]),a("p",[t._v("Also values that are referenced require explicit typings.\nThe following will raise an error:")]),t._v(" "),a("div",{staticClass:"language-ream extra-class"},[a("pre",{pre:!0,attrs:{class:"language-ream"}},[a("code",[a("span",{pre:!0,attrs:{class:"token header"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("#")]),t._v(" CountryYear")]),a("span",{pre:!0,attrs:{class:"token keyValuePair"}},[t._v("\n"),a("span",{pre:!0,attrs:{class:"token key"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" country (String)")]),a("span",{pre:!0,attrs:{class:"token semiolon punctuation"}},[t._v(": ")]),a("span",{pre:!0,attrs:{class:"token value string"}},[t._v("Belgium")])]),a("span",{pre:!0,attrs:{class:"token keyValuePair"}},[t._v("\n"),a("span",{pre:!0,attrs:{class:"token key"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" year")]),a("span",{pre:!0,attrs:{class:"token semiolon punctuation"}},[t._v(": ")]),a("span",{pre:!0,attrs:{class:"token value string"}},[t._v("2020")])]),a("span",{pre:!0,attrs:{class:"token keyValuePair"}},[t._v("\n"),a("span",{pre:!0,attrs:{class:"token key"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" unique_id (fn -> String)")]),a("span",{pre:!0,attrs:{class:"token semiolon punctuation"}},[t._v(": ")]),a("span",{pre:!0,attrs:{class:"token value string"}},[t._v("`")]),a("span",{pre:!0,attrs:{class:"token value number"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("$")]),t._v("country + '_' + "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("$")])]),a("span",{pre:!0,attrs:{class:"token value string"}},[t._v("year`")])]),t._v("\n")])])]),a("p",[t._v("Example 2:")]),t._v(" "),a("div",{staticClass:"language-ream extra-class"},[a("pre",{pre:!0,attrs:{class:"language-ream"}},[a("code",[a("span",{pre:!0,attrs:{class:"token header"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("#")]),t._v(" The Benelux Union")]),a("span",{pre:!0,attrs:{class:"token keyValuePair"}},[t._v("\n"),a("span",{pre:!0,attrs:{class:"token key"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" members")]),a("span",{pre:!0,attrs:{class:"token value string"}},[t._v(":")])]),a("span",{pre:!0,attrs:{class:"token listItem"}},[t._v("\n"),a("span",{pre:!0,attrs:{class:"token value string"}},[t._v("  ")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("*")]),a("span",{pre:!0,attrs:{class:"token value string"}},[t._v(" Belgium")])]),a("span",{pre:!0,attrs:{class:"token listItem"}},[t._v("\n"),a("span",{pre:!0,attrs:{class:"token value string"}},[t._v("  ")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("*")]),a("span",{pre:!0,attrs:{class:"token value string"}},[t._v(" Netherlands")])]),a("span",{pre:!0,attrs:{class:"token listItem"}},[t._v("\n"),a("span",{pre:!0,attrs:{class:"token value string"}},[t._v("  ")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("*")]),a("span",{pre:!0,attrs:{class:"token value string"}},[t._v(" Luxembourg")])]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyValuePair"}},[a("span",{pre:!0,attrs:{class:"token key"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" total_pop (fn -> Number): `THIS:")]),a("span",{pre:!0,attrs:{class:"token value string"}},[t._v(":Country$pop.SUM()`")])]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token header"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("##")]),t._v(" Country")]),a("span",{pre:!0,attrs:{class:"token keyValuePair"}},[t._v("\n"),a("span",{pre:!0,attrs:{class:"token key"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" name")]),a("span",{pre:!0,attrs:{class:"token semiolon punctuation"}},[t._v(": ")]),a("span",{pre:!0,attrs:{class:"token value string"}},[t._v("Belgium")])]),a("span",{pre:!0,attrs:{class:"token keyValuePair"}},[t._v("\n"),a("span",{pre:!0,attrs:{class:"token key"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" pop (Number)")]),a("span",{pre:!0,attrs:{class:"token semiolon punctuation"}},[t._v(": ")]),a("span",{pre:!0,attrs:{class:"token value number"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("$")]),t._v("11433256"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("$")])])]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token header"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("##")]),t._v(" Country")]),a("span",{pre:!0,attrs:{class:"token keyValuePair"}},[t._v("\n"),a("span",{pre:!0,attrs:{class:"token key"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" name")]),a("span",{pre:!0,attrs:{class:"token semiolon punctuation"}},[t._v(": ")]),a("span",{pre:!0,attrs:{class:"token value string"}},[t._v("Netherlands")])]),a("span",{pre:!0,attrs:{class:"token keyValuePair"}},[t._v("\n"),a("span",{pre:!0,attrs:{class:"token key"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" pop (Number)")]),a("span",{pre:!0,attrs:{class:"token semiolon punctuation"}},[t._v(": ")]),a("span",{pre:!0,attrs:{class:"token value number"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("$")]),t._v("17332850"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("$")])])]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token header"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("##")]),t._v(" Country")]),a("span",{pre:!0,attrs:{class:"token keyValuePair"}},[t._v("\n"),a("span",{pre:!0,attrs:{class:"token key"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" name")]),a("span",{pre:!0,attrs:{class:"token semiolon punctuation"}},[t._v(": ")]),a("span",{pre:!0,attrs:{class:"token value string"}},[t._v("Luxembourg")])]),a("span",{pre:!0,attrs:{class:"token keyValuePair"}},[t._v("\n"),a("span",{pre:!0,attrs:{class:"token key"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" pop (Number)")]),a("span",{pre:!0,attrs:{class:"token semiolon punctuation"}},[t._v(": ")]),a("span",{pre:!0,attrs:{class:"token value number"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("$")]),t._v("619900"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("$")])])]),t._v("\n")])])]),a("p",[t._v("Attributes from sub-entries can be referenced by the namespace "),a("code",[t._v("<SubEntry Name>")]),t._v(".")]),t._v(" "),a("p",[t._v("Example 3:")]),t._v(" "),a("div",{staticClass:"language-ream extra-class"},[a("pre",{pre:!0,attrs:{class:"language-ream"}},[a("code",[a("span",{pre:!0,attrs:{class:"token header"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("#")]),t._v(" Country")]),a("span",{pre:!0,attrs:{class:"token keyValuePair"}},[t._v("\n"),a("span",{pre:!0,attrs:{class:"token key"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" name")]),a("span",{pre:!0,attrs:{class:"token semiolon punctuation"}},[t._v(": ")]),a("span",{pre:!0,attrs:{class:"token value string"}},[t._v("United States of America")])]),a("span",{pre:!0,attrs:{class:"token keyValuePair"}},[t._v("\n"),a("span",{pre:!0,attrs:{class:"token key"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" captial")]),a("span",{pre:!0,attrs:{class:"token semiolon punctuation"}},[t._v(": ")]),a("span",{pre:!0,attrs:{class:"token value string"}},[t._v("Washington, D.C.")])]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token header"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("##")]),t._v(" City")]),a("span",{pre:!0,attrs:{class:"token keyValuePair"}},[t._v("\n"),a("span",{pre:!0,attrs:{class:"token key"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" name")]),a("span",{pre:!0,attrs:{class:"token semiolon punctuation"}},[t._v(": ")]),a("span",{pre:!0,attrs:{class:"token value string"}},[t._v("New York")])]),a("span",{pre:!0,attrs:{class:"token keyValuePair"}},[t._v("\n"),a("span",{pre:!0,attrs:{class:"token key"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" is_capital (fn -> Boolean): `THIS$name == THIS:")]),a("span",{pre:!0,attrs:{class:"token value string"}},[t._v(":SUPER$capital`")])]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token header"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("##")]),t._v(" City")]),a("span",{pre:!0,attrs:{class:"token keyValuePair"}},[t._v("\n"),a("span",{pre:!0,attrs:{class:"token key"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" name")]),a("span",{pre:!0,attrs:{class:"token semiolon punctuation"}},[t._v(": ")]),a("span",{pre:!0,attrs:{class:"token value string"}},[t._v("Washington, D.C.")])]),a("span",{pre:!0,attrs:{class:"token keyValuePair"}},[t._v("\n"),a("span",{pre:!0,attrs:{class:"token key"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("-")]),t._v(" is_capital (fn -> Boolean): `THIS$name == THIS:")]),a("span",{pre:!0,attrs:{class:"token value string"}},[t._v(":SUPER$capital`")])]),t._v("\n")])])]),a("p",[t._v("Attributes from a parent entry can be referenced by the "),a("code",[t._v("SUPER")]),t._v(" namespace.")])])])}),[],!1,null,null,null);s.default=e.exports}}]);