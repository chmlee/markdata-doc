(window.webpackJsonp=window.webpackJsonp||[]).push([[18],{383:function(s,t,a){"use strict";a.r(t);var e=a(25),n=Object(e.a)({},(function(){var s=this,t=s.$createElement,a=s._self._c||t;return a("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[a("h1",{attrs:{id:"variable"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#variable"}},[s._v("#")]),s._v(" Variable")]),s._v(" "),a("p",[s._v("All REAM file starts with a Level-1 Entry Header, in the form of")]),s._v(" "),a("div",{staticClass:"language-ream extra-class"},[a("pre",{pre:!0,attrs:{class:"language-ream"}},[a("code",[a("span",{pre:!0,attrs:{class:"token header"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("#")]),s._v(" <Level-1 Entry Header>")]),s._v("\n")])])]),a("p",[s._v("We will discuss what "),a("a",{attrs:{href:"/ream-doc/Language/Basics/Entry"}},[s._v("entries")]),s._v(" are later.\nFor now, just see this as the title of your dataset.")]),s._v(" "),a("hr"),s._v(" "),a("p",[a("code",[s._v("<variable>")]),s._v(" assigns a "),a("code",[s._v("<value>")]),s._v(" to a "),a("code",[s._v("<key>")]),s._v(", in the form of")]),s._v(" "),a("div",{staticClass:"language-ream extra-class"},[a("pre",{pre:!0,attrs:{class:"language-ream"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyValuePair"}},[a("span",{pre:!0,attrs:{class:"token key"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("-")]),s._v(" <key>")]),a("span",{pre:!0,attrs:{class:"token semiolon punctuation"}},[s._v(": ")]),a("span",{pre:!0,attrs:{class:"token value string"}},[s._v("<value>")])]),s._v("\n")])])]),a("p",[s._v("Note that a space is required after the dash and colon.")]),s._v(" "),a("p",[a("code",[s._v("<key>")]),s._v(" can't be empty.\nIt may contain any upper and lowercase letters ("),a("code",[s._v("A-Za-z")]),s._v("), digits ("),a("code",[s._v("0-9")]),s._v(") and spaces ("),a("code",[s._v("U+0020")]),s._v("), but must start with a letter.")]),s._v(" "),a("p",[a("code",[s._v("<value>")]),s._v(" can be any of the following types:")]),s._v(" "),a("ul",[a("li",[a("a",{attrs:{href:"#string"}},[s._v("String")])]),s._v(" "),a("li",[a("a",{attrs:{href:"#number"}},[s._v("Number")])]),s._v(" "),a("li",[a("a",{attrs:{href:"#boolean"}},[s._v("Boolean")])]),s._v(" "),a("li",[a("a",{attrs:{href:"#list"}},[s._v("List")])])]),s._v(" "),a("h2",{attrs:{id:"string"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#string"}},[s._v("#")]),s._v(" String")]),s._v(" "),a("p",[s._v("Example:")]),s._v(" "),a("div",{staticClass:"language-ream extra-class"},[a("pre",{pre:!0,attrs:{class:"language-ream"}},[a("code",[a("span",{pre:!0,attrs:{class:"token header"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("#")]),s._v(" Example")]),a("span",{pre:!0,attrs:{class:"token keyValuePair"}},[s._v("\n"),a("span",{pre:!0,attrs:{class:"token key"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("-")]),s._v(" string")]),a("span",{pre:!0,attrs:{class:"token semiolon punctuation"}},[s._v(": ")]),a("span",{pre:!0,attrs:{class:"token value string"}},[s._v("value")])]),a("span",{pre:!0,attrs:{class:"token keyValuePair"}},[s._v("\n"),a("span",{pre:!0,attrs:{class:"token key"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("-")]),s._v(" long string")]),a("span",{pre:!0,attrs:{class:"token semiolon punctuation"}},[s._v(": ")]),a("span",{pre:!0,attrs:{class:"token value string"}},[s._v("Hello World")])]),a("span",{pre:!0,attrs:{class:"token keyValuePair"}},[s._v("\n"),a("span",{pre:!0,attrs:{class:"token key"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("-")]),s._v(" quoted string")]),a("span",{pre:!0,attrs:{class:"token semiolon punctuation"}},[s._v(": ")]),a("span",{pre:!0,attrs:{class:"token value string"}},[s._v('"quote"')])]),s._v("\n")])])]),a("EditorLite-EditorLite",{attrs:{item:"string"}}),s._v(" "),a("p",[s._v("There is not need to quote strings.\nQuotation marks will be preserved.")]),s._v(" "),a("p",[s._v("Values can't contain line breaks.\nThe following will raise an error:")]),s._v(" "),a("div",{staticClass:"language-ream extra-class"},[a("div",{staticClass:"highlight-lines"},[a("br"),a("br"),a("div",{staticClass:"highlighted"},[s._v("Â ")]),a("br"),a("br")]),a("pre",{pre:!0,attrs:{class:"language-ream"}},[a("code",[a("span",{pre:!0,attrs:{class:"token header"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("#")]),s._v(" Example")]),a("span",{pre:!0,attrs:{class:"token keyValuePair"}},[s._v("\n"),a("span",{pre:!0,attrs:{class:"token key"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("-")]),s._v(" key 1")]),a("span",{pre:!0,attrs:{class:"token semiolon punctuation"}},[s._v(": ")]),a("span",{pre:!0,attrs:{class:"token value string"}},[s._v("first line")])]),s._v("\n         second line\n"),a("span",{pre:!0,attrs:{class:"token keyValuePair"}},[a("span",{pre:!0,attrs:{class:"token key"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("-")]),s._v(" key 2")]),a("span",{pre:!0,attrs:{class:"token semiolon punctuation"}},[s._v(": ")]),a("span",{pre:!0,attrs:{class:"token value string"}},[s._v("value")])]),s._v("\n")])])]),a("details",{staticClass:"custom-block details"},[a("summary",[s._v("Known Issue")]),s._v(" "),a("p",[s._v("The current parser is able to parse the example.\nIt will read everything before and including "),a("code",[s._v("- key 1: first line")]),s._v(", then stop parsing and return whatever has been parsed, ignoring the rest of the file.\nSo the example is equivalent to:")]),s._v(" "),a("div",{staticClass:"language-ream extra-class"},[a("pre",{pre:!0,attrs:{class:"language-ream"}},[a("code",[a("span",{pre:!0,attrs:{class:"token header"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("#")]),s._v(" Example")]),a("span",{pre:!0,attrs:{class:"token keyValuePair"}},[s._v("\n"),a("span",{pre:!0,attrs:{class:"token key"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("-")]),s._v(" key 1")]),a("span",{pre:!0,attrs:{class:"token semiolon punctuation"}},[s._v(": ")]),a("span",{pre:!0,attrs:{class:"token value string"}},[s._v("first line")])]),s._v("\n")])])]),a("p",[s._v("Error handling will be improved in future versions.")])]),s._v(" "),a("h2",{attrs:{id:"number"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#number"}},[s._v("#")]),s._v(" Number")]),s._v(" "),a("p",[s._v("Numbers are surrounded by dollar signs ("),a("code",[s._v("$")]),s._v(").")]),s._v(" "),a("p",[s._v("Example:")]),s._v(" "),a("div",{staticClass:"language-ream extra-class"},[a("pre",{pre:!0,attrs:{class:"language-ream"}},[a("code",[a("span",{pre:!0,attrs:{class:"token header"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("#")]),s._v(" Example")]),a("span",{pre:!0,attrs:{class:"token keyValuePair"}},[s._v("\n"),a("span",{pre:!0,attrs:{class:"token key"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("-")]),s._v(" number 1")]),a("span",{pre:!0,attrs:{class:"token semiolon punctuation"}},[s._v(": ")]),a("span",{pre:!0,attrs:{class:"token value number"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("$")]),s._v("1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("$")])])]),a("span",{pre:!0,attrs:{class:"token keyValuePair"}},[s._v("\n"),a("span",{pre:!0,attrs:{class:"token key"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("-")]),s._v(" number 2")]),a("span",{pre:!0,attrs:{class:"token semiolon punctuation"}},[s._v(": ")]),a("span",{pre:!0,attrs:{class:"token value number"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("$")]),s._v("-2"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("$")])])]),a("span",{pre:!0,attrs:{class:"token keyValuePair"}},[s._v("\n"),a("span",{pre:!0,attrs:{class:"token key"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("-")]),s._v(" number 3")]),a("span",{pre:!0,attrs:{class:"token semiolon punctuation"}},[s._v(": ")]),a("span",{pre:!0,attrs:{class:"token value number"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("$")]),s._v("3.1415926"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("$")])])]),s._v("\n")])])]),a("EditorLite-EditorLite",{attrs:{item:"number"}}),s._v(" "),a("p",[s._v("If characters are placed outside the dollar signs, the entire value will be stored as a string, preserving the dollar signs.")]),s._v(" "),a("p",[s._v("Example:")]),s._v(" "),a("div",{staticClass:"language-ream extra-class"},[a("pre",{pre:!0,attrs:{class:"language-ream"}},[a("code",[a("span",{pre:!0,attrs:{class:"token header"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("#")]),s._v(" Example")]),a("span",{pre:!0,attrs:{class:"token keyValuePair"}},[s._v("\n"),a("span",{pre:!0,attrs:{class:"token key"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("-")]),s._v(" number")]),a("span",{pre:!0,attrs:{class:"token semiolon punctuation"}},[s._v(": ")]),a("span",{pre:!0,attrs:{class:"token value number"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("$")]),s._v("1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("$")])])]),a("span",{pre:!0,attrs:{class:"token keyValuePair"}},[s._v("\n"),a("span",{pre:!0,attrs:{class:"token key"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("-")]),s._v(" not number 1")]),a("span",{pre:!0,attrs:{class:"token semiolon punctuation"}},[s._v(": ")]),a("span",{pre:!0,attrs:{class:"token value string"}},[s._v("a")]),a("span",{pre:!0,attrs:{class:"token value number"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("$")]),s._v("1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("$")])])]),a("span",{pre:!0,attrs:{class:"token keyValuePair"}},[s._v("\n"),a("span",{pre:!0,attrs:{class:"token key"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("-")]),s._v(" not number 2")]),a("span",{pre:!0,attrs:{class:"token semiolon punctuation"}},[s._v(": ")]),a("span",{pre:!0,attrs:{class:"token value number"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("$")]),s._v("1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("$")])]),a("span",{pre:!0,attrs:{class:"token value string"}},[s._v("b")])]),s._v("\n")])])]),a("EditorLite-EditorLite",{attrs:{item:"notNumber"}}),s._v(" "),a("details",{staticClass:"custom-block details"},[a("summary",[s._v("Known Issue")]),s._v(" "),a("p",[s._v("The current parser will identify every value surrounded by dollar signs as a number.\nSo")]),s._v(" "),a("div",{staticClass:"language-ream extra-class"},[a("pre",{pre:!0,attrs:{class:"language-ream"}},[a("code",[a("span",{pre:!0,attrs:{class:"token header"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("#")]),s._v(" Example")]),a("span",{pre:!0,attrs:{class:"token keyValuePair"}},[s._v("\n"),a("span",{pre:!0,attrs:{class:"token key"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("-")]),s._v(" number")]),a("span",{pre:!0,attrs:{class:"token semiolon punctuation"}},[s._v(": ")]),a("span",{pre:!0,attrs:{class:"token value number"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("$")]),s._v("1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("$")])])]),a("span",{pre:!0,attrs:{class:"token keyValuePair"}},[s._v("\n"),a("span",{pre:!0,attrs:{class:"token key"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("-")]),s._v(" not a number")]),a("span",{pre:!0,attrs:{class:"token semiolon punctuation"}},[s._v(": ")]),a("span",{pre:!0,attrs:{class:"token value number"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("$")]),s._v("abc"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("$")])])]),s._v("\n")])])]),a("p",[s._v("generates")]),s._v(" "),a("div",{staticClass:"language-csv extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[s._v("1,abc\n")])])]),a("p",[s._v("instead of")]),s._v(" "),a("div",{staticClass:"language-csv extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[s._v("1,$abc$\n")])])]),a("p",[s._v("even though "),a("code",[s._v("abc")]),s._v(" is not a valid number.")]),s._v(" "),a("p",[s._v("Strict number type checking will be implemented in the future.")])]),s._v(" "),a("h2",{attrs:{id:"boolean"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#boolean"}},[s._v("#")]),s._v(" Boolean")]),s._v(" "),a("p",[s._v("Boolean values are "),a("code",[s._v("`TRUE`")]),s._v(" and "),a("code",[s._v("`FALSE`")]),s._v(", both uppercase and surrounded by backticks ("),a("code",[s._v("`")]),s._v(").")]),s._v(" "),a("p",[s._v("Example:")]),s._v(" "),a("div",{staticClass:"language-ream extra-class"},[a("pre",{pre:!0,attrs:{class:"language-ream"}},[a("code",[a("span",{pre:!0,attrs:{class:"token header"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("#")]),s._v(" Example")]),a("span",{pre:!0,attrs:{class:"token keyValuePair"}},[s._v("\n"),a("span",{pre:!0,attrs:{class:"token key"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("-")]),s._v(" bool 1")]),a("span",{pre:!0,attrs:{class:"token semiolon punctuation"}},[s._v(": ")]),a("span",{pre:!0,attrs:{class:"token value string"}},[s._v("`TRUE`")])]),a("span",{pre:!0,attrs:{class:"token keyValuePair"}},[s._v("\n"),a("span",{pre:!0,attrs:{class:"token key"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("-")]),s._v(" bool 2")]),a("span",{pre:!0,attrs:{class:"token semiolon punctuation"}},[s._v(": ")]),a("span",{pre:!0,attrs:{class:"token value string"}},[s._v("`FALSE`")])]),a("span",{pre:!0,attrs:{class:"token keyValuePair"}},[s._v("\n"),a("span",{pre:!0,attrs:{class:"token key"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("-")]),s._v(" not bool 1")]),a("span",{pre:!0,attrs:{class:"token semiolon punctuation"}},[s._v(": ")]),a("span",{pre:!0,attrs:{class:"token value boolean"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("true"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")])])]),a("span",{pre:!0,attrs:{class:"token keyValuePair"}},[s._v("\n"),a("span",{pre:!0,attrs:{class:"token key"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("-")]),s._v(" not bool 2")]),a("span",{pre:!0,attrs:{class:"token semiolon punctuation"}},[s._v(": ")]),a("span",{pre:!0,attrs:{class:"token value string"}},[s._v("FALSE")])]),s._v("\n")])])]),a("EditorLite-EditorLite",{attrs:{item:"boolean"}}),s._v(" "),a("p",[s._v("Note that boolean values must be exact matches.\nValues not surrounded by batckticks or not uppercased will be stored as strings.")]),s._v(" "),a("h2",{attrs:{id:"list"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#list"}},[s._v("#")]),s._v(" List")]),s._v(" "),a("p",[s._v("A list is a sequence of strings, numbers, and/or boolean, in the form of:")]),s._v(" "),a("div",{staticClass:"language-ream extra-class"},[a("pre",{pre:!0,attrs:{class:"language-ream"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyValuePair"}},[a("span",{pre:!0,attrs:{class:"token key"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("-")]),s._v(" <key>")]),a("span",{pre:!0,attrs:{class:"token value string"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token listItem"}},[s._v("\n"),a("span",{pre:!0,attrs:{class:"token value string"}},[s._v("  ")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("*")]),a("span",{pre:!0,attrs:{class:"token value string"}},[s._v(" <item>")])]),a("span",{pre:!0,attrs:{class:"token listItem"}},[s._v("\n"),a("span",{pre:!0,attrs:{class:"token value string"}},[s._v("  ")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("*")]),a("span",{pre:!0,attrs:{class:"token value string"}},[s._v(" <item>")])]),s._v("\n  ...\n"),a("span",{pre:!0,attrs:{class:"token listItem"}},[a("span",{pre:!0,attrs:{class:"token value string"}},[s._v("  ")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("*")]),a("span",{pre:!0,attrs:{class:"token value string"}},[s._v(" <item>")])]),s._v("\n")])])]),a("p",[a("code",[s._v("<item>")]),s._v(" should be in separate lines, following an asterisk ("),a("code",[s._v("*")]),s._v(")")]),s._v(" "),a("p",[s._v("Example:")]),s._v(" "),a("div",{staticClass:"language-ream extra-class"},[a("pre",{pre:!0,attrs:{class:"language-ream"}},[a("code",[a("span",{pre:!0,attrs:{class:"token header"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("#")]),s._v(" Example")]),a("span",{pre:!0,attrs:{class:"token keyValuePair"}},[s._v("\n"),a("span",{pre:!0,attrs:{class:"token key"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("-")]),s._v(" list of strings")]),a("span",{pre:!0,attrs:{class:"token value string"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token listItem"}},[s._v("\n"),a("span",{pre:!0,attrs:{class:"token value string"}},[s._v("  ")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("*")]),a("span",{pre:!0,attrs:{class:"token value string"}},[s._v(" item 1")])]),a("span",{pre:!0,attrs:{class:"token listItem"}},[s._v("\n"),a("span",{pre:!0,attrs:{class:"token value string"}},[s._v("  ")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("*")]),a("span",{pre:!0,attrs:{class:"token value string"}},[s._v(" item 2")])]),a("span",{pre:!0,attrs:{class:"token listItem"}},[s._v("\n"),a("span",{pre:!0,attrs:{class:"token value string"}},[s._v("  ")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("*")]),a("span",{pre:!0,attrs:{class:"token value string"}},[s._v(" item 3")])]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyValuePair"}},[a("span",{pre:!0,attrs:{class:"token key"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("-")]),s._v(" list of numbers")]),a("span",{pre:!0,attrs:{class:"token value string"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token listItem"}},[s._v("\n"),a("span",{pre:!0,attrs:{class:"token value string"}},[s._v("  ")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("*")]),a("span",{pre:!0,attrs:{class:"token value string"}},[s._v(" ")]),a("span",{pre:!0,attrs:{class:"token value number"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("$")]),s._v("1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("$")])])]),a("span",{pre:!0,attrs:{class:"token listItem"}},[s._v("\n"),a("span",{pre:!0,attrs:{class:"token value string"}},[s._v("  ")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("*")]),a("span",{pre:!0,attrs:{class:"token value string"}},[s._v(" ")]),a("span",{pre:!0,attrs:{class:"token value number"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("$")]),s._v("-2"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("$")])])]),a("span",{pre:!0,attrs:{class:"token listItem"}},[s._v("\n"),a("span",{pre:!0,attrs:{class:"token value string"}},[s._v("  ")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("*")]),a("span",{pre:!0,attrs:{class:"token value string"}},[s._v(" ")]),a("span",{pre:!0,attrs:{class:"token value number"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("$")]),s._v("3.1415926"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("$")])])]),s._v("\n")])])]),a("EditorLite-EditorLite",{attrs:{item:"list1"}}),s._v(" "),a("div",{staticClass:"custom-block tip"},[a("p",{staticClass:"custom-block-title"},[s._v("TIP")]),s._v(" "),a("p",[s._v("By default, items in lists would be joined as strings with semicolons as separators")])]),s._v(" "),a("p",[s._v("Recall that REAM is indentation insensitive.\nSpaces before asterisks are not required, but two spaces are recommended.")]),s._v(" "),a("div",{staticClass:"language-ream extra-class"},[a("pre",{pre:!0,attrs:{class:"language-ream"}},[a("code",[a("span",{pre:!0,attrs:{class:"token header"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("#")]),s._v(" Example")]),a("span",{pre:!0,attrs:{class:"token keyValuePair"}},[s._v("\n"),a("span",{pre:!0,attrs:{class:"token key"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("-")]),s._v(" still a list")]),a("span",{pre:!0,attrs:{class:"token value string"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token listItem"}},[s._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("*")]),a("span",{pre:!0,attrs:{class:"token value string"}},[s._v(" item 1")])]),a("span",{pre:!0,attrs:{class:"token listItem"}},[s._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("*")]),a("span",{pre:!0,attrs:{class:"token value string"}},[s._v(" item 2")])]),a("span",{pre:!0,attrs:{class:"token listItem"}},[s._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("*")]),a("span",{pre:!0,attrs:{class:"token value string"}},[s._v(" item 3")])]),s._v("\n")])])]),a("EditorLite-EditorLite",{attrs:{item:"list2"}}),s._v(" "),a("p",[s._v("Empty lines between list items are allowed, but discouraged:")]),s._v(" "),a("div",{staticClass:"language-ream extra-class"},[a("pre",{pre:!0,attrs:{class:"language-ream"}},[a("code",[a("span",{pre:!0,attrs:{class:"token header"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("#")]),s._v(" Example")]),a("span",{pre:!0,attrs:{class:"token keyValuePair"}},[s._v("\n"),a("span",{pre:!0,attrs:{class:"token key"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("-")]),s._v(" still a list")]),a("span",{pre:!0,attrs:{class:"token value string"}},[s._v(":")])]),a("span",{pre:!0,attrs:{class:"token listItem"}},[s._v("\n"),a("span",{pre:!0,attrs:{class:"token value string"}},[s._v("  ")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("*")]),a("span",{pre:!0,attrs:{class:"token value string"}},[s._v(" item 1")])]),a("span",{pre:!0,attrs:{class:"token listItem"}},[s._v("\n\n"),a("span",{pre:!0,attrs:{class:"token value string"}},[s._v("  ")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("*")]),a("span",{pre:!0,attrs:{class:"token value string"}},[s._v(" item 2")])]),a("span",{pre:!0,attrs:{class:"token listItem"}},[s._v("\n"),a("span",{pre:!0,attrs:{class:"token value string"}},[s._v("  ")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("*")]),a("span",{pre:!0,attrs:{class:"token value string"}},[s._v(" item 3")])]),s._v("\n")])])]),a("EditorLite-EditorLite",{attrs:{item:"list3"}})],1)}),[],!1,null,null,null);t.default=n.exports}}]);